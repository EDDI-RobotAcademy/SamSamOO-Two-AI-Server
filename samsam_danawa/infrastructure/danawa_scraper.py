from bs4 import BeautifulSoup
import requests
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

from samsam_danawa.domain.product import DanawaProduct
from samsam_danawa.domain.review import DanawaReview

# ğŸ” ë‹¤ë‚˜ì™€ ìƒí’ˆ ê²€ìƒ‰ (ìˆ˜ì •ëœ ë²„ì „)
def get_image_url(img_el):
    if not img_el:
        return ""

    # 1) lazy-load ë°©ì‹
    url = img_el.get("data-original") \
          or img_el.get("data-src") \
          or img_el.get("data-img") \
          or img_el.get("src") \
          or ""

    # 2) í”„ë¡œí† ì½œì„ ëˆ„ë½í•œ "//img..." í˜•íƒœ â†’ "https:" ë¶™ì´ê¸°
    if url.startswith("//"):
        url = "https:" + url

    return url


def search_danawa_products(query: str):
    url = f"https://search.danawa.com/dsearch.php?query={query}"
    headers = {"User-Agent": "Mozilla/5.0"}
    res = requests.get(url, headers=headers)
    if res.status_code != 200:
        return []

    soup = BeautifulSoup(res.text, "html.parser")
    products = []

    items = soup.select("div.prod_main_info")

    for item in items:
        name_el = item.select_one(".prod_name a")
        price_el = item.select_one(".price_sect strong")
        img_el = item.select_one(".thumb_image img")

        if not name_el:
            continue

        link = name_el.get("href")
        product_id = link.split("pcode=")[-1]

        # ì´ë¯¸ì§€ URL ë¶„ë¦¬ ë¡œì§
        image_url = get_image_url(img_el)

        product = DanawaProduct(
            product_id=product_id,
            name=name_el.text.strip(),
            price=price_el.text.strip() if price_el else "",
            mall="ë‹¤ë‚˜ì™€",
            image=image_url,
            link=link
        )

        products.append(product)

    return products


# â­ ë‹¤ë‚˜ì™€ ë¦¬ë·° ìˆ˜ì§‘ (ìˆ˜ì •ëœ ë²„ì „)
def get_danawa_reviews(product_id: str):
    url = f"https://prod.danawa.com/info/?pcode={product_id}"

    options = webdriver.ChromeOptions()
    options.add_argument("--headless=new")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--window-size=1920,1080")

    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    driver.get(url)

    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "#danawa-prodBlog-productOpinion-list"))
        )
    except Exception:
        time.sleep(2)

    soup = BeautifulSoup(driver.page_source, "html.parser")
    driver.quit()

    reviews = []
    review_items = soup.select("li.cmt_item")

    for item in review_items:
        nickname = item.select_one(".id_name strong")
        date = item.select_one(".date")
        content = item.select_one(".danawa-prodBlog-productOpinion-clazz-content")

        review = DanawaReview(
            user=nickname.text.strip() if nickname else "ì•Œ ìˆ˜ ì—†ìŒ",
            date=date.text.strip() if date else "",
            text=content.text.strip() if content else "",
        )
        reviews.append(review)

    return reviews
